# -*- coding: utf-8 -*-
"""Involution

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ol6hUz-IA9NU3S9IcgtdLKYNXq7o330G
"""

from google.colab import drive
drive.mount('/content/drive')

!unzip /content/drive/MyDrive/database.zip

!pip install --upgrade keras

import os

os.environ["KERAS_BACKEND"] = "tensorflow"

import tensorflow as tf
import keras
import matplotlib.pyplot as plt

# Set seed for reproducibility.
tf.random.set_seed(42)

import matplotlib.pyplot as plt
import numpy as np
import cv2
import sys
from PIL import ImageFont, ImageDraw, Image
import glob

# Get list of directories
listf = sorted(glob.glob("/content/database/mel_spectrum_all_train/*"))
print("List of folders in all_train:", listf)
print("Number of folders:", len(listf))

# Initialize variables
L = 0
num_classes = min(11, len(listf))  # Ensure num_classes doesn't exceed len(listf)

# Count total images
for i in range(0, num_classes):
    listg = glob.glob(listf[i] + "/*png")
    for m in range(0, len(listg)):
        L = L + 1

# Prepare trainData and labels arrays
s = [48, 48]
trainData = np.full((L, s[0], s[1], 3), 1)
labels = np.full(L, 1)

# Process images
cnt = 0
for i in range(0, num_classes):
    listg = glob.glob(listf[i] + "/*png")
    for m in range(0, len(listg)):
        imgname = listg[m]
        image = cv2.imread(imgname)
        image = cv2.resize(image, (s[1], s[0]))
        trainData[cnt, :, :, :] = image
        labels[cnt] = i
        cnt = cnt + 1

print("Data processing complete. Total images:", L)

import tensorflow as tf
import glob
import numpy as np

# Define data paths
train_dir = "/content/database/mel_spectrum_all_train/"
test_dir = "/content/database/melspectrum_all_test/"

# Define image size and batch size
img_size = (48, 48)
batch_size = 256

# Create label mapping
label_mapping = {
    'cel': 0, 'cla': 1, 'flu': 2, 'gac': 3, 'gel': 4,
    'org': 5, 'pia': 6, 'sax': 7, 'tru': 8, 'vio': 9, 'voice': 10,
    'voi': 10 # Add this mapping
}

# Load training images and labels
train_image_paths = glob.glob(train_dir + "/*/*png")  # Ensures it finds png files in subfolders
train_labels = [label_mapping.get(path.split("/")[-2], -1) for path in train_image_paths] # Changed to use dict.get() for safer key access

# Check if any label is -1 (unknown) and handle it appropriately.
if -1 in train_labels:
    print("WARNING: Unknown labels found. Check your dataset and label mapping.")
# Load training images
def load_image(path):
    img = tf.keras.utils.load_img(path)  # Use keras.utils.load_img to load image
    img = tf.keras.utils.img_to_array(img)  # Convert image to array
    img = tf.image.resize(img, (32,32))
    img = img / 255.0
    return img

# Check if train_image_paths is empty and print its content
if not train_image_paths:
    print("train_image_paths is empty. Check your train_dir:", train_dir)
    print("Files found in train_dir:")
    import os
    for filename in os.listdir(train_dir):
        print(filename)
else:
    train_images = np.array([load_image(path) for path in train_image_paths])
    train_labels = np.array(train_labels, dtype=np.int32)

    # Split dataset into training and validation sets
    from sklearn.model_selection import train_test_split

    X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, random_state=32)

    # Create TensorFlow datasets
    train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32)
    val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(32)

    print("Training dataset:", train_ds)
    print("Validation dataset:", val_ds)

class Involution(keras.layers.Layer):
    def __init__(
        self, channel, group_number, kernel_size, stride, reduction_ratio, name
    ):
        super().__init__(name=name)

        # Initialize the parameters.
        self.channel = channel
        self.group_number = group_number
        self.kernel_size = kernel_size
        self.stride = stride
        self.reduction_ratio = reduction_ratio

    def build(self, input_shape):
        # Get the shape of the input.
        (_, height, width, num_channels) = input_shape

        # Scale the height and width with respect to the strides.
        height = height // self.stride
        width = width // self.stride

        # Define a layer that average pools the input tensor
        # if stride is more than 1.
        self.stride_layer = (
            keras.layers.AveragePooling2D(
                pool_size=self.stride, strides=self.stride, padding="same"
            )
            if self.stride > 1
            else tf.identity
        )
        # Define the kernel generation layer.
        self.kernel_gen = keras.Sequential(
            [
                keras.layers.Conv2D(
                    filters=self.channel // self.reduction_ratio, kernel_size=1
                ),
                keras.layers.BatchNormalization(),
                keras.layers.ReLU(),
                keras.layers.Conv2D(
                    filters=self.kernel_size * self.kernel_size * self.group_number,
                    kernel_size=1,
                ),
            ]
        )
        # Define reshape layers
        self.kernel_reshape = keras.layers.Reshape(
            target_shape=(
                height,
                width,
                self.kernel_size * self.kernel_size,
                1,
                self.group_number,
            )
        )
        self.input_patches_reshape = keras.layers.Reshape(
            target_shape=(
                height,
                width,
                self.kernel_size * self.kernel_size,
                num_channels // self.group_number,
                self.group_number,
            )
        )
        self.output_reshape = keras.layers.Reshape(
            target_shape=(height, width, num_channels)
        )

    def call(self, x):
        # Generate the kernel with respect to the input tensor.
        # B, H, W, K*K*G
        kernel_input = self.stride_layer(x)
        kernel = self.kernel_gen(kernel_input)

        # reshape the kerenl
        # B, H, W, K*K, 1, G
        kernel = self.kernel_reshape(kernel)

        # Extract input patches.
        # B, H, W, K*K*C
        input_patches = tf.image.extract_patches(
            images=x,
            sizes=[1, self.kernel_size, self.kernel_size, 1],
            strides=[1, self.stride, self.stride, 1],
            rates=[1, 1, 1, 1],
            padding="SAME",
        )

        # Reshape the input patches to align with later operations.
        # B, H, W, K*K, C//G, G
        input_patches = self.input_patches_reshape(input_patches)

        # Compute the multiply-add operation of kernels and patches.
        # B, H, W, K*K, C//G, G
        output = tf.multiply(kernel, input_patches)
        # B, H, W, C//G, G
        output = tf.reduce_sum(output, axis=3)

        # Reshape the output kernel.
        # B, H, W, C
        output = self.output_reshape(output)

        # Return the output tensor and the kernel.
        return output, kernel

# Define the input tensor.
input_tensor = tf.random.normal((32, 256, 256, 3))

# Compute involution with stride 1.
output_tensor, _ = Involution(
    channel=3, group_number=1, kernel_size=5, stride=1, reduction_ratio=1, name="inv_1"
)(input_tensor)
print(f"with stride 1 ouput shape: {output_tensor.shape}")

# Compute involution with stride 2.
output_tensor, _ = Involution(
    channel=3, group_number=1, kernel_size=5, stride=2, reduction_ratio=1, name="inv_2"
)(input_tensor)
print(f"with stride 2 ouput shape: {output_tensor.shape}")

# Compute involution with stride 1, channel 16 and reduction ratio 2.
output_tensor, _ = Involution(
    channel=16, group_number=1, kernel_size=5, stride=1, reduction_ratio=2, name="inv_3"
)(input_tensor)
print(
    "with channel 16 and reduction ratio 2 ouput shape: {}".format(output_tensor.shape)
)

import matplotlib.pyplot as plt

class_names = ['cel', 'cla', 'flu', 'gac', 'gel', 'org', 'pia', 'sax', 'tru', 'vio', 'voice']

import random

random_indices = random.sample(range(len(train_images)), 25)

plt.figure(figsize=(10, 10))
for i, idx in enumerate(random_indices):
    plt.subplot(5, 5, i + 1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[idx])
    plt.xlabel(class_names[train_labels[idx]])

plt.tight_layout()
plt.show()

print("building the convolution model...")

conv_model = keras.Sequential([
    keras.layers.InputLayer(input_shape=(32,32, 3)),
    keras.layers.Conv2D(256, (3, 3), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.MaxPooling2D((2,2)),
    keras.layers.Dropout(0.2),

    keras.layers.Conv2D(256, (3, 3), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.MaxPooling2D((2,2)),
    keras.layers.Dropout(0.2),

    keras.layers.Conv2D(256, (3, 3), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.Flatten(),

    keras.layers.Dense(256, activation='relu'),
    keras.layers.Dropout(0.2),
    keras.layers.Dense(11, activation='softmax')
])

print("compiling the convolution model...")

conv_model.compile(
    optimizer="adam",
    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=["accuracy"],
)

print("conv model training...")

conv_hist = conv_model.fit(train_ds, epochs=100, validation_data=val_ds)

import time
import tensorflow as tf
from tensorflow import keras

# Measure training time
start_time = time.time()

conv_hist = conv_model.fit(train_ds, epochs=100, validation_data=val_ds)

end_time = time.time()

print(f"Total Training Time: {end_time - start_time:.2f} seconds")

# Build the involution model.
print("building the involution model...")

inputs = keras.Input(shape=(32, 32, 3))
x, _ = Involution(
    channel=3, group_number=1, kernel_size=3, stride=1, reduction_ratio=2, name="inv_1"
)(inputs)
x = keras.layers.ReLU()(x)
x = keras.layers.MaxPooling2D((3, 3))(x)
x, _ = Involution(
    channel=3, group_number=1, kernel_size=3, stride=1, reduction_ratio=2, name="inv_2"
)(x)
x = keras.layers.ReLU()(x)
x = keras.layers.MaxPooling2D((3, 3))(x)
x, _ = Involution(
    channel=3, group_number=1, kernel_size=3, stride=1, reduction_ratio=2, name="inv_3"
)(x)
x = keras.layers.ReLU()(x)
x = keras.layers.Flatten()(x)
x = keras.layers.Dense(64, activation="relu")(x)
outputs = keras.layers.Dense(11)(x)

inv_model = keras.Model(inputs=[inputs], outputs=[outputs], name="inv_model")

# Compile the mode with the necessary loss function and optimizer.
print("compiling the involution model...")
inv_model.compile(
    optimizer="adam",
    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=["accuracy"],
)

# train the model
print("inv model training...")
inv_hist = inv_model.fit(train_ds, epochs=100, validation_data=val_ds)

import time
import tensorflow as tf
from tensorflow import keras

# Measure training time
start_time = time.time()

conv_hist = inv_model.fit(train_ds, epochs=100, validation_data=val_ds)

end_time = time.time()

print(f"Total Training Time: {end_time - start_time:.2f} seconds")

conv_model.summary()

inv_model.summary()

layer_names = ["inv_1", "inv_2", "inv_3"]
outputs = [inv_model.get_layer(name).output[1] for name in layer_names]
vis_model = keras.Model(inv_model.input, outputs)

fig, axes = plt.subplots(nrows=10, ncols=4, figsize=(10, 30))

for ax, train_image in zip(axes, train_images[:10]):
    (inv1_kernel, inv2_kernel, inv3_kernel) = vis_model.predict(train_image[None, ...])
    inv1_kernel = tf.reduce_sum(inv1_kernel, axis=[-1, -2, -3])
    inv2_kernel = tf.reduce_sum(inv2_kernel, axis=[-1, -2, -3])
    inv3_kernel = tf.reduce_sum(inv3_kernel, axis=[-1, -2, -3])

    ax[0].imshow(keras.utils.array_to_img(train_image))
    ax[0].set_title("Input Image")

    ax[1].imshow(keras.utils.array_to_img(inv1_kernel[0, ..., None]))
    ax[1].set_title("Involution Kernel 1")

    ax[2].imshow(keras.utils.array_to_img(inv2_kernel[0, ..., None]))
    ax[2].set_title("Involution Kernel 2")

    ax[3].imshow(keras.utils.array_to_img(inv3_kernel[0, ..., None]))
    ax[3].set_title("Involution Kernel 3")

import matplotlib.pyplot as plt
import numpy as np
import cv2
import sys
from PIL import ImageFont, ImageDraw, Image
import glob

# Get list of directories, ensure the path is correct
listf = sorted(glob.glob("/content/database/melspectrum_all_test/*"))
print(listf)  # Print listf to verify its contents
L = 0
num_classes = 11

# Handle case where listf is empty
if not listf:
    print("Error: No directories found at the specified path.")
    sys.exit(1)  # Exit the script with an error code

# Initialize labels array with the correct size
labels = np.empty(0, dtype=int)  # Initialize as an empty array

# Restrict loop to actual number of folders found
for i in range(0, min(num_classes, len(listf))):
    listg = glob.glob(listf[i] + "/*png")
    L += len(listg)  # Update L with the number of images in each class
    # Append labels for the current class to the labels array
    labels = np.append(labels, np.full(len(listg), i, dtype=int))

s = [32, 32]
testData = np.full((L, s[0], s[1], 3), 1)
cnt = 0
F = []

for i in range(0, min(num_classes, len(listf))):  # Ensure i stays within bounds
    listg = sorted(glob.glob(listf[i] + "/*png"))
    for m in range(0, len(listg)):
        imgname = listg[m]
        image = cv2.imread(imgname)
        image = cv2.resize(image, (s[1], s[0]))
        testData[cnt, :, :, :] = image
        # Labels are already assigned, no need to reassign here
        # labels[cnt] = i
        cnt = cnt + 1

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report

test_images = testData.astype('float32') / 255
test_labels = labels  # Use the 'labels' variable instead of 'testlabels'
print(test_images.shape)
print(test_labels.shape)
labels = inv_model.predict(test_images)
test_out = np.argmax(np.round(labels),axis=1)
print(test_labels) # Print test_labels instead of testlabels
print(test_out)
test_loss, test_acc = inv_model.evaluate(test_images, test_labels)
#print("Test loss: {0:.6f}, Test accuracy: {1:.6f}".format(test_loss,test_acc))
print('Test accuracy:', test_acc*100)
cm = confusion_matrix(test_labels, test_out) # Use test_labels instead of testlabels
print(cm)
cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
print(cm.diagonal())
a = inv_model.predict(test_images)
#print(a)
import pandas as pd
#pd.DataFrame(a).to_csv("a.csv")
target_names = ['cel', 'cla', 'flu', 'gac', 'gel','org', 'pia','sax','tru','vio','voice']
print(classification_report(test_labels, test_out, target_names=target_names)) # Use test_labels instead of testlabels
# Plot confusion matrix
import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, cmap='Blues')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()
plt.figure(figsize=(20, 5))

plt.subplot(1, 2, 1)
plt.title("Convolution Loss")
plt.plot(conv_hist.history["loss"], label="loss")
plt.plot(conv_hist.history["val_loss"], label="val_loss")
plt.legend()

plt.subplot(1, 2, 2)
plt.title("Involution Loss")
plt.plot(inv_hist.history["loss"], label="loss")
plt.plot(inv_hist.history["val_loss"], label="val_loss")
plt.legend()

plt.show()

plt.figure(figsize=(20, 5))

plt.subplot(1, 2, 1)
plt.title("Convolution Accuracy")
plt.plot(conv_hist.history["accuracy"], label="accuracy")
plt.plot(conv_hist.history["val_accuracy"], label="val_accuracy")
plt.legend()

plt.subplot(1, 2, 2)
plt.title("Involution Accuracy")
plt.plot(inv_hist.history["accuracy"], label="accuracy")
plt.plot(inv_hist.history["val_accuracy"], label="val_accuracy")
plt.legend()

plt.show()



